{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bdPB7273pSVr"
   },
   "source": [
    "# Assignment 7\n",
    "\n",
    "Train a Transformer model for Machine Translation from Russian to English.  \n",
    "Dataset: http://data.statmt.org/wmt18/translation-task/training-parallel-nc-v13.tgz   \n",
    "Make all source and target text to lower case.  \n",
    "Use following tokenization for english:  \n",
    "```\n",
    "import sentencepiece as spm\n",
    "\n",
    "...\n",
    "spm.SentencePieceTrainer.Train('--input=data/text.en --model_prefix=bpe_en --vocab_size=32000 --character_coverage=0.98 --model_type=bpe')\n",
    "\n",
    "tok_en = spm.SentencePieceProcessor()\n",
    "tok_en.load('bpe_en.model')\n",
    "\n",
    "TGT = data.Field(\n",
    "    fix_length=50,\n",
    "    init_token='<s>',\n",
    "    eos_token='</s>',\n",
    "    lower=True,\n",
    "    tokenize = lambda x: tok_en.encode_as_pieces(x),\n",
    "    batch_first=True,\n",
    ")\n",
    "\n",
    "...\n",
    "TGT.build_vocab(..., min_freq=5)\n",
    "...\n",
    "\n",
    "```\n",
    "Score: corpus-bleu `nltk.translate.bleu_score.corpus_bleu`  \n",
    "Use last 1000 sentences for model evalutation (test dataset).  \n",
    "Use your target sequence tokenization for BLEU score.  \n",
    "Use max_len=50 for sequence prediction.  \n",
    "\n",
    "\n",
    "Hint: You may consider much smaller model, than shown in the example.  \n",
    "\n",
    "Baselines:  \n",
    "[4 point] BLEU = 0.05  \n",
    "[6 point] BLEU = 0.10  \n",
    "[9 point] BLEU = 0.15  \n",
    "\n",
    "[1 point] Share weights between target embeddings and output dense layer. Notice, they have the same shape.\n",
    "\n",
    "\n",
    "Readings:\n",
    "1. BLUE score how to https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
    "1. Transformer code and comments http://nlp.seas.harvard.edu/2018/04/03/attention.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "E4_WCxsIpfOb",
    "outputId": "06f4878a-d902-4f59-becc-d422baa6e08f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "k5fuE9mLdX3J",
    "outputId": "953418cd-bc22-469d-a809-88cccdcb6f00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "ONdQOrOFrZlN",
    "outputId": "3d06db8b-75a0-47b1-86b7-048a59d2f30c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\r",
      "\u001b[K     |▎                               | 10kB 22.6MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 20kB 28.1MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 30kB 30.3MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 40kB 31.7MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 51kB 34.0MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 61kB 36.3MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 71kB 34.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 81kB 35.2MB/s eta 0:00:01\r",
      "\u001b[K     |██▉                             | 92kB 36.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 102kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 112kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 122kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 133kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 143kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 153kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 163kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 174kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 184kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 194kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 204kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 215kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 225kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 235kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 245kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 256kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 266kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 276kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 286kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 296kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 307kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 317kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 327kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 337kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 348kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 358kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 368kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 378kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 389kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 399kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 409kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 419kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 430kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 440kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 450kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 460kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 471kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 481kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 491kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 501kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 512kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 522kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 532kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 542kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 552kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 563kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 573kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 583kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 593kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 604kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 614kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 624kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▌            | 634kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 645kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 655kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 665kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 675kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 686kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 696kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 706kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 716kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 727kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 737kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 747kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 757kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 768kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 778kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 788kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 798kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 808kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 819kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 829kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 839kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 849kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 860kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 870kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 880kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 890kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 901kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 911kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 921kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 931kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 942kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 952kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 962kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 972kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 983kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 993kB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 1.0MB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 1.0MB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 1.0MB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 1.0MB 35.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.0MB 35.8MB/s \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.85\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "U2jlAMg06Nj3",
    "outputId": "4ae0d99f-048a-4722-ab02-666a4c29227c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88_pmzcbrFD4"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "heVeHNLJpSVs"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from tqdm.notebook import tqdm\n",
    "from torchtext import datasets, data\n",
    "#from tqdm.notebook import tqdm\n",
    "import sentencepiece as spm\n",
    "\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "H3zf-GYErxCd",
    "outputId": "49d5b80f-1f20-4214-abcf-e07bc2c92844"
   },
   "outputs": [
    {
     "ename": "MessageError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2f24f400ed36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls drive/My\\\\ Drive/Ru-En'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_monitor_process\u001b[0;34m(parent_pty, epoll, p, cmd, update_stdin_widget)\u001b[0m\n\u001b[1;32m    227\u001b[0m       \u001b[0mnew_echo_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_settings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtermios\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mECHO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mecho_status\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnew_echo_status\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_echo_status\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0mecho_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_echo_status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mecho_updater\u001b[0;34m(new_echo_status)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;31m# https://github.com/googlecolab/colabtools/blob/56e4dbec7c4fa09fad51b60feb5c786c69d688c6/google/colab/_message.py#L100.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mupdate_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_update_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'echo'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_echo_status\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mupdate_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;32myield\u001b[0m \u001b[0mecho_updater\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMessageError\u001b[0m: Error: Cell has no view"
     ]
    }
   ],
   "source": [
    "# opening archive in google colab\n",
    "# archive lies in drive/My Drive/Ru-En\n",
    "\n",
    "!ls drive/My\\ Drive/Ru-En"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ohnCFivNrzy2"
   },
   "outputs": [],
   "source": [
    "# if using google colab\n",
    "import os, sys, tarfile\n",
    "\n",
    "tar_path = 'drive/My Drive/training-parallel-nc-v13.tgz'\n",
    "tar = tarfile.open(tar_path, 'r')\n",
    "\n",
    "for item in tar:\n",
    "    tar.extract(item, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NfylUqh5sDtL",
    "outputId": "4da69b32-944d-44b8-f161-9c2e5ca531df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive  __pycache__  sample_data  training-parallel-nc-v13  transformer.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xfbY-54kpSVx",
    "outputId": "2bd68185-96aa-4c17-9257-6e7dfcaa0dfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize english \n",
    "with open('training-parallel-nc-v13/news-commentary-v13.ru-en.en') as f:\n",
    "    with open('training-parallel-nc-v13/text.en', 'w') as out:\n",
    "            out.write(f.read().lower())\n",
    "        \n",
    "spm.SentencePieceTrainer.Train('--input=training-parallel-nc-v13/text.en --model_prefix=bpe_en --vocab_size=32000 --character_coverage=0.98 --model_type=bpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3ouWoigQpSV3",
    "outputId": "e2065119-06e7-404c-d46f-d0a3db3ba45f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize russian\n",
    "with open('training-parallel-nc-v13/news-commentary-v13.ru-en.ru') as f:\n",
    "    with open('training-parallel-nc-v13/text.ru', 'w') as out:\n",
    "            out.write(f.read().lower())\n",
    "\n",
    "spm.SentencePieceTrainer.Train('--input=training-parallel-nc-v13/text.ru --model_prefix=bpe_ru --vocab_size=32000 --character_coverage=0.98 --model_type=bpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GcXaD41SpSV7"
   },
   "outputs": [],
   "source": [
    "tok_ru = spm.SentencePieceProcessor()\n",
    "tok_ru.load('bpe_ru.model')\n",
    "\n",
    "tok_en = spm.SentencePieceProcessor()\n",
    "tok_en.load('bpe_en.model')\n",
    "\n",
    "SRC = data.Field(\n",
    "    fix_length=50,\n",
    "    init_token='<s>',\n",
    "    eos_token='</s>',\n",
    "    lower=True,\n",
    "    tokenize = lambda x: tok_ru.encode_as_pieces(x),\n",
    "    batch_first=True,\n",
    ")\n",
    "\n",
    "TGT = data.Field(\n",
    "    fix_length=50,\n",
    "    init_token='<s>',\n",
    "    eos_token='</s>',\n",
    "    lower=True,\n",
    "    tokenize = lambda x: tok_en.encode_as_pieces(x),\n",
    "    batch_first=True,\n",
    ")\n",
    "\n",
    "fields = (('src', SRC), ('tgt', TGT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "efHZs5dbpSV_",
    "outputId": "ff9c7f66-72c0-418c-e6df-dc736d27a88b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235159it [00:53, 4413.48it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('training-parallel-nc-v13/text.ru') as f:\n",
    "    src_snt = list(map(str.strip, f.readlines()))\n",
    "    \n",
    "with open('training-parallel-nc-v13/text.en') as f:\n",
    "    tgt_snt = list(map(str.strip, f.readlines()))\n",
    "    \n",
    "examples = [data.Example.fromlist(x, fields) for x in tqdm(zip(src_snt, tgt_snt))]\n",
    "test = data.Dataset(examples[-1000:], fields)\n",
    "train, valid = data.Dataset(examples[:-1000], fields).split(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "twbYFN4spSWD",
    "outputId": "818e1bc9-1f15-4d8e-be55-c95ea8e2ba04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: ▁ « сторон ники ▁членства ▁в ▁ес ▁готовы ▁на ▁вс ё , ▁ – ▁предупредил ▁в ▁мину вшие ▁выходные ▁ ф ара ж ▁своих ▁товари щей , ▁выступающих ▁за ▁ж ё сткий ▁выход ▁из ▁ес . ▁ – ▁у ▁них ▁большинство ▁в ▁парламенте , ▁и ▁если ▁мы ▁не ▁само органи зу емся , ▁мы ▁можем ▁потерять ▁свою ▁историческую ▁победу , ▁которой ▁является ▁брексит » .\n",
      "tgt: ▁ “ the ▁remain ▁side ▁are ▁making ▁all ▁the ▁running , ” ▁farage ▁warned ▁his ▁fellow ▁hardline ▁lea vers ▁this ▁weekend . ▁ “ they ▁have ▁a ▁ma j ority ▁in ▁parliament , ▁and ▁unless ▁we ▁get ▁ourselves ▁organi z ed ▁we ▁could ▁lose ▁the ▁historic ▁victory ▁that ▁was ▁bre x it . ”\n"
     ]
    }
   ],
   "source": [
    "print('src: ' + \" \".join(train.examples[100].src))\n",
    "print('tgt: ' + \" \".join(train.examples[100].tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "y2zfXJRopSWM",
    "outputId": "a413058e-8da5-47b9-ea24-8e3d7cd10dfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210743, 23416, 1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(valid), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3YWplTatpSWR"
   },
   "outputs": [],
   "source": [
    "TGT.build_vocab(train, min_freq=5)\n",
    "SRC.build_vocab(train, min_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dHZUYavspSWW"
   },
   "outputs": [],
   "source": [
    "from transformer import make_model, Batch\n",
    "\n",
    "    \n",
    "class BucketIteratorWrapper(DataLoader):\n",
    "    __initialized = False\n",
    "\n",
    "    def __init__(self, iterator: data.Iterator):\n",
    "#         super(BucketIteratorWrapper,self).__init__()\n",
    "        self.batch_size = iterator.batch_size\n",
    "        self.num_workers = 1\n",
    "        self.collate_fn = None\n",
    "        self.pin_memory = False\n",
    "        self.drop_last = False\n",
    "        self.timeout = 0\n",
    "        self.worker_init_fn = None\n",
    "        self.sampler = iterator\n",
    "        self.batch_sampler = iterator\n",
    "        self.__initialized = True\n",
    "\n",
    "    def __iter__(self):\n",
    "        return map(\n",
    "            lambda batch: Batch(batch.src, batch.tgt, pad=TGT.vocab.stoi['<pad>']),\n",
    "            self.batch_sampler.__iter__()\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)\n",
    "    \n",
    "class MyCriterion(nn.Module):\n",
    "    def __init__(self, pad_idx):\n",
    "        super(MyCriterion, self).__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction='sum', ignore_index=pad_idx)\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        x = x.contiguous().permute(0,2,1)\n",
    "        ntokens = (target != self.pad_idx).data.sum()\n",
    "        \n",
    "        return self.criterion(x, target) / ntokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "colab_type": "code",
    "id": "XMuu61k0x2LA",
    "outputId": "b6ab21cf-b4fb-40f7-e3ad-992bf180fe15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
      "\r",
      "\u001b[K     |▋                               | 10kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 20kB 24.5MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 30kB 28.9MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 40kB 32.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 51kB 27.9MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 61kB 29.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 71kB 24.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 81kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 92kB 27.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 102kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 112kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 122kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 133kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 143kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 153kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 163kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 174kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 184kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 194kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 204kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 215kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 225kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 235kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 245kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 256kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 266kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 276kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 286kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 296kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 307kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 317kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 327kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 337kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 348kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 358kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 368kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 378kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 389kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 399kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 409kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 419kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 430kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 440kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 450kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 460kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 471kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 481kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 491kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 501kB 25.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
      "\r",
      "\u001b[K     |▍                               | 10kB 30.3MB/s eta 0:00:01\r",
      "\u001b[K     |▊                               | 20kB 39.2MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 30kB 44.2MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 40kB 48.2MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 51kB 50.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 61kB 53.8MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 71kB 53.5MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 81kB 54.6MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 92kB 56.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 102kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 112kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 122kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 133kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 143kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 153kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 163kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 174kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 184kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 194kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 204kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 215kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 225kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 235kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 245kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 256kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 266kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 276kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 286kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 296kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 307kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 317kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 327kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 337kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 348kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 358kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 368kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 378kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 389kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 399kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 409kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 419kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 430kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 440kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 450kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 460kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 471kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 481kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 491kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 501kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 512kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 522kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 532kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 542kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 552kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 563kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 573kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 583kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 593kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 604kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 614kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 624kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 634kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 645kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 655kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 665kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 675kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 686kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 696kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 706kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 716kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 727kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 737kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 747kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 757kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 768kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 778kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 788kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 798kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 808kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 819kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 829kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 839kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 849kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 860kB 51.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 870kB 51.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
      "Collecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 60.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=5c2d0fd776e83226441a6bd866d942b94db2aebca0926a7a20d19c8f05a30ae2\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.38 tokenizers-0.5.2 transformers-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "QWlF8dm7x6GA",
    "outputId": "485b6704-c703-4df1-b4b8-985cf50344bf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWSnLISPpSWc"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "batch_size = 100\n",
    "num_epochs = 3 #10\n",
    "\n",
    "train_iter, valid_iter, test_iter = data.BucketIterator.splits((train, valid, test), \n",
    "                                              batch_sizes=(batch_size, batch_size, batch_size), \n",
    "                                  sort_key=lambda x: len(x.src),\n",
    "                                  shuffle=True,\n",
    "                                  device=DEVICE,\n",
    "                                  sort_within_batch=False)\n",
    "                                  \n",
    "train_iter = BucketIteratorWrapper(train_iter)\n",
    "valid_iter = BucketIteratorWrapper(valid_iter)\n",
    "test_iter = BucketIteratorWrapper(test_iter)\n",
    "\n",
    "\n",
    "#pad_idx = TGT.vocab.stoi[\"<blank>\"]\n",
    "model = make_model(len(SRC.vocab), len(TGT.vocab), N=6, \n",
    "               d_model=64, d_ff=128, h=8, dropout=0.1) # d_model=256, d_ff=512, h=8, dropout=0.1\n",
    "model = model.to(DEVICE)\n",
    "criterion = MyCriterion(pad_idx=TGT.vocab.stoi[\"<pad>\"])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer=optimizer, \n",
    "                                             num_warmup_steps=0.1*num_epochs*len(train_iter)//batch_size, \n",
    "                                             num_training_steps=num_epochs*len(train_iter)//batch_size, \n",
    "                                             last_epoch=-1)\n",
    "\n",
    "# share weights\n",
    "\n",
    "#model.src_embed[0].proj.weight = model.tgt_embed[0].lut.weight\n",
    "model.generator.proj.weight = model.tgt_embed[0].lut.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yTNu8ykJ1fBH"
   },
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "        \n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQJi-Md01gXv"
   },
   "outputs": [],
   "source": [
    "optimizer = NoamOpt(model.src_embed[0].d_model, 1, 2000,\n",
    "        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jwsSlxl9pSWh",
    "outputId": "bac6ddd7-2716-4c27-d693-525427f5e337"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 10.250384\n",
      "Epoch Step: 201 Loss: 8.217693\n",
      "Epoch Step: 401 Loss: 6.775377\n",
      "Epoch Step: 601 Loss: 6.317687\n",
      "Epoch Step: 801 Loss: 5.840505\n",
      "Epoch Step: 1001 Loss: 5.660727\n",
      "Epoch Step: 1201 Loss: 5.316370\n",
      "Epoch Step: 1401 Loss: 5.208490\n",
      "Epoch Step: 1601 Loss: 5.083454\n",
      "Epoch Step: 1801 Loss: 4.872099\n",
      "Epoch Step: 2001 Loss: 4.710423\n",
      "train tensor(6.0023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch Step: 1 Loss: 3.683186\n",
      "Epoch Step: 201 Loss: 4.704116\n",
      "valid tensor(4.4587, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 4.721891\n",
      "Epoch Step: 201 Loss: 4.533014\n",
      "Epoch Step: 401 Loss: 4.445936\n",
      "Epoch Step: 601 Loss: 4.240973\n",
      "Epoch Step: 801 Loss: 4.369490\n",
      "Epoch Step: 1001 Loss: 4.144696\n",
      "Epoch Step: 1201 Loss: 4.154868\n",
      "Epoch Step: 1401 Loss: 4.061755\n",
      "Epoch Step: 1601 Loss: 4.039318\n",
      "Epoch Step: 1801 Loss: 4.063687\n",
      "Epoch Step: 2001 Loss: 3.799658\n",
      "train tensor(4.2823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch Step: 1 Loss: 2.599038\n",
      "Epoch Step: 201 Loss: 3.869589\n",
      "valid tensor(3.6305, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 3.901573\n",
      "Epoch Step: 201 Loss: 3.914845\n",
      "Epoch Step: 401 Loss: 3.849926\n",
      "Epoch Step: 601 Loss: 3.820953\n",
      "Epoch Step: 801 Loss: 3.682456\n",
      "Epoch Step: 1001 Loss: 3.838163\n",
      "Epoch Step: 1201 Loss: 3.676849\n",
      "Epoch Step: 1401 Loss: 3.896335\n",
      "Epoch Step: 1601 Loss: 3.848556\n",
      "Epoch Step: 1801 Loss: 3.876398\n",
      "Epoch Step: 2001 Loss: 3.684056\n",
      "train tensor(3.7678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch Step: 1 Loss: 2.281339\n",
      "Epoch Step: 201 Loss: 3.460480\n",
      "valid tensor(3.2694, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 3.527274\n",
      "Epoch Step: 201 Loss: 3.683208\n",
      "Epoch Step: 401 Loss: 3.556189\n",
      "Epoch Step: 601 Loss: 3.505782\n",
      "Epoch Step: 801 Loss: 3.411890\n",
      "Epoch Step: 1001 Loss: 3.397948\n",
      "Epoch Step: 1201 Loss: 3.481203\n",
      "Epoch Step: 1401 Loss: 3.590069\n",
      "Epoch Step: 1601 Loss: 3.615188\n",
      "Epoch Step: 1801 Loss: 3.303973\n",
      "Epoch Step: 2001 Loss: 3.402136\n",
      "train tensor(3.4967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch Step: 1 Loss: 2.115866\n",
      "Epoch Step: 201 Loss: 3.242270\n",
      "valid tensor(3.0874, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 3.208081\n",
      "Epoch Step: 201 Loss: 3.313372\n",
      "Epoch Step: 401 Loss: 3.388015\n",
      "Epoch Step: 601 Loss: 3.305273\n",
      "Epoch Step: 801 Loss: 3.438171\n",
      "Epoch Step: 1001 Loss: 3.468734\n",
      "Epoch Step: 1201 Loss: 3.224514\n",
      "Epoch Step: 1401 Loss: 3.553580\n",
      "Epoch Step: 1601 Loss: 3.371566\n",
      "Epoch Step: 1801 Loss: 3.588178\n",
      "Epoch Step: 2001 Loss: 3.379536\n",
      "train tensor(3.3419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch Step: 1 Loss: 2.076016\n",
      "Epoch Step: 201 Loss: 3.140233\n",
      "valid tensor(2.9897, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 2.918254\n",
      "Epoch Step: 201 Loss: 3.282845\n",
      "Epoch Step: 401 Loss: 3.061132\n",
      "Epoch Step: 601 Loss: 3.145400\n",
      "Epoch Step: 801 Loss: 3.086362\n",
      "Epoch Step: 1001 Loss: 3.393026\n",
      "Epoch Step: 1201 Loss: 3.322715\n",
      "Epoch Step: 1401 Loss: 3.320884\n",
      "Epoch Step: 1601 Loss: 3.252934\n",
      "Epoch Step: 1801 Loss: 3.147717\n",
      "Epoch Step: 2001 Loss: 3.304284\n",
      "train tensor(3.2445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch Step: 1 Loss: 1.959533\n",
      "Epoch Step: 201 Loss: 3.089910\n",
      "valid tensor(2.9237, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 3.167403\n",
      "Epoch Step: 201 Loss: 3.079447\n",
      "Epoch Step: 401 Loss: 3.087362\n",
      "Epoch Step: 601 Loss: 3.135539\n",
      "Epoch Step: 801 Loss: 3.107913\n",
      "Epoch Step: 1001 Loss: 3.252574\n",
      "Epoch Step: 1201 Loss: 3.048033\n",
      "Epoch Step: 1401 Loss: 3.257060\n",
      "Epoch Step: 1601 Loss: 3.267989\n",
      "Epoch Step: 1801 Loss: 3.412631\n",
      "Epoch Step: 2001 Loss: 3.025818\n",
      "train tensor(3.1763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch Step: 1 Loss: 1.942002\n",
      "Epoch Step: 201 Loss: 3.020291\n",
      "valid tensor(2.8775, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 3.174767\n",
      "Epoch Step: 201 Loss: 3.069033\n",
      "Epoch Step: 401 Loss: 3.264070\n",
      "Epoch Step: 601 Loss: 2.991987\n",
      "Epoch Step: 801 Loss: 3.126142\n",
      "Epoch Step: 1001 Loss: 3.236750\n",
      "Epoch Step: 1201 Loss: 2.953814\n",
      "Epoch Step: 1401 Loss: 3.273584\n",
      "Epoch Step: 1601 Loss: 3.228620\n",
      "Epoch Step: 1801 Loss: 3.369024\n",
      "Epoch Step: 2001 Loss: 3.270095\n",
      "train tensor(3.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch Step: 1 Loss: 1.901261\n",
      "Epoch Step: 201 Loss: 2.963590\n",
      "valid tensor(2.8451, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 2.993616\n",
      "Epoch Step: 201 Loss: 3.153637\n",
      "Epoch Step: 401 Loss: 2.953053\n",
      "Epoch Step: 601 Loss: 3.190016\n",
      "Epoch Step: 801 Loss: 3.121238\n",
      "Epoch Step: 1001 Loss: 3.200380\n",
      "Epoch Step: 1201 Loss: 3.021760\n",
      "Epoch Step: 1401 Loss: 2.915479\n",
      "Epoch Step: 1601 Loss: 3.222557\n",
      "Epoch Step: 1801 Loss: 3.043198\n",
      "Epoch Step: 2001 Loss: 3.137093\n",
      "train tensor(3.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch Step: 1 Loss: 1.897526\n",
      "Epoch Step: 201 Loss: 2.935367\n",
      "valid tensor(2.8166, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 2.802202\n",
      "Epoch Step: 201 Loss: 3.177551\n",
      "Epoch Step: 401 Loss: 3.028685\n",
      "Epoch Step: 601 Loss: 3.154438\n",
      "Epoch Step: 801 Loss: 3.177768\n",
      "Epoch Step: 1001 Loss: 3.153084\n",
      "Epoch Step: 1201 Loss: 3.019558\n",
      "Epoch Step: 1401 Loss: 3.264547\n",
      "Epoch Step: 1601 Loss: 2.950103\n",
      "Epoch Step: 1801 Loss: 2.977646\n",
      "Epoch Step: 2001 Loss: 3.090411\n",
      "train tensor(3.0545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch Step: 1 Loss: 1.862317\n",
      "Epoch Step: 201 Loss: 2.915157\n",
      "valid tensor(2.7994, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(data_iter, model, criterion):\n",
    "    total_loss = 0\n",
    "    #data_iter = tqdm(data_iter)\n",
    "    counter = 0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        model.zero_grad()\n",
    "        out = model.forward(batch)\n",
    "        #print(torch.max(out[0], dim=-1)[1])\n",
    "        loss = criterion(out, batch.tgt_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss\n",
    "        #data_iter.set_postfix(loss = loss)\n",
    "        counter += 1\n",
    "        if i % 200 == 1:\n",
    "            print(\"Epoch Step: %d Loss: %f\" %\n",
    "                    (i, loss))\n",
    "    return total_loss / counter\n",
    "\n",
    "\n",
    "def valid_epoch(data_iter, model, criterion):\n",
    "    total_loss = 0\n",
    "    #data_iter = tqdm(data_iter)\n",
    "    counter = 0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out = model.forward(batch)\n",
    "        loss = criterion(out, batch.tgt_y)\n",
    "        total_loss += loss\n",
    "        #data_iter.set_postfix(loss = loss)\n",
    "        counter += 1\n",
    "        if i % 200 == 1:\n",
    "            print(\"Epoch Step: %d Loss: %f\" %\n",
    "                    (i, loss))\n",
    "    return total_loss / counter\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    loss = train_epoch(train_iter, model, criterion)\n",
    "    print('train', loss)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss = valid_epoch(valid_iter, model, criterion)\n",
    "        scheduler.step(loss)\n",
    "        print('valid', loss)\n",
    "\n",
    "    torch.save(model.state_dict(), 'drive/My Drive/check.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JZEERkpKe5bE",
    "outputId": "b12ed921-6ab0-406a-e04e-542eb82cb8a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('drive/My Drive/check.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XbP1-zQ5g4Vd"
   },
   "outputs": [],
   "source": [
    "start_symbol_id = TGT.vocab.stoi[\"<s>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t5T6XMvvglW6"
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(src.size(0), 1).fill_(start_symbol_id).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        prob = model.decode((ys).long(), \n",
    "                           (subsequent_mask(ys.size(1))\n",
    "                                    .type_as(src.data)),\n",
    "                           memory,\n",
    "                           src_mask\n",
    "                           )\n",
    "        _, next_word = torch.max(prob[:, -1, :], dim = -1)\n",
    "        ys = torch.cat([ys, next_word.unsqueeze(-1)], dim=1)\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "venKcmc3f2FB"
   },
   "outputs": [],
   "source": [
    "def beam_search(model, src, src_mask, max_len=10, k=5):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(src.size(0), 1).fill_(start_symbol_id).long().to(src.device)\n",
    "    k_beam = [(0, ys)]\n",
    "\n",
    "    for l in range(max_len):\n",
    "        all_k_beams = []\n",
    "        for prob, sent_pred in k_beam:\n",
    "            pred = model.decode(sent_pred.long(), \n",
    "                           subsequent_mask(sent_pred.size(1))\n",
    "                                    .type_as(src.data),\n",
    "                           memory,\n",
    "                           src_mask\n",
    "                           )\n",
    "            _, possible_k = torch.topk(pred[:, -1, :], k=k, dim=-1)\n",
    "\n",
    "            all_k_beams += [\n",
    "                (\n",
    "                    sum([pred[0, i, sent_pred[0, i]].item() for i in range(l)]) + pred[0, -1, next_word].item(),\n",
    "                    torch.cat([sent_pred, next_word.resize(sent_pred.size(0), 1)], dim=1)\n",
    "                )\n",
    "                for next_word in possible_k.view(k, -1)\n",
    "            ]\n",
    "\n",
    "        k_beam = sorted(all_k_beams, key=lambda x: x[0])[-k:]\n",
    "\n",
    "    return k_beam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6V6TjvFFpSWq",
    "outputId": "a43a9070-08bc-476c-980f-39bde39c733a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:362: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Source: риск цунами\n",
      "Translation:\n",
      "systemic risk\n",
      "systemic risk\n",
      "systemic risk\n",
      "systemic risk\n",
      "systemic risk\n",
      "Target: the risk tsunami\n",
      "\n",
      "Source: новый трамп?\n",
      "Translation:\n",
      "it is america?\n",
      "it is america?\n",
      "it is america?\n",
      "it is america?\n",
      "it is america?\n",
      "Target: a new trump?\n",
      "\n",
      "Source: он не вернется.\n",
      "Translation:\n",
      "not it return.\n",
      "not it return.\n",
      "not it return.\n",
      "not it return.\n",
      "not it return.\n",
      "Target: he is not coming back.\n",
      "\n",
      "Source: индийская хиллари клинтон?\n",
      "Translation:\n",
      "hillary clinton can hillary hillary\n",
      "hillary clinton can hillary hillary\n",
      "hillary clinton can hillary hillary\n",
      "hillary clinton can hillary hillary\n",
      "hillary clinton can hillary hillary\n",
      "Target: india’s hillary clinton?\n",
      "\n",
      "Source: третья бреттон-вудская система\n",
      "Translation:\n",
      "an third authoritarian regime\n",
      "an third authoritarian regime\n",
      "an third authoritarian system\n",
      "an third authoritarian system\n",
      "an third authoritarian system\n",
      "Target: bretton woods iii\n",
      "\n",
      "Source: балансовый отчет арабской весны\n",
      "Translation:\n",
      "arab spring’s great report\n",
      "arab spring’s balance report\n",
      "arab spring’s great list\n",
      "arab spring’s great report\n",
      "arab spring’s balance report\n",
      "Target: the arab spring’s balance sheet\n",
      "\n",
      "Source: лишь 27% выбрали америку.\n",
      "Translation:\n",
      "the only 27% of america has been committed to\n",
      "the only 27% of america has been committed america\n",
      "the only 27% of america has been committed.\n",
      "the only 27% of america has been chosen.\n",
      "the only 27% of america has been elected.\n",
      "Target: just 27% chose america.\n",
      "\n",
      "Source: процветание распространилось относительно широко.\n",
      "Translation:\n",
      "growth has been spreading about widely widely, but there\n",
      "growth has been spreading about widely widely, but it\n",
      "growth has been spreading about widely widely, too.\n",
      "growth has been spreading about widely widely.\n",
      "growth has been spreading about widely widely widely.\n",
      "Target: prosperity has been relatively widely shared.\n",
      "\n",
      "Source: это явное изменение подхода.\n",
      "Translation:\n",
      "this is an apparent change.\n",
      "this is an apparent change.\n",
      "this is an apparent shift.\n",
      "this is an apparent change.\n",
      "this is an apparent change.\n",
      "Target: clearly, change is in the air.\n",
      "\n",
      "Source: но что случится в действительности?\n",
      "Translation:\n",
      "what happens can happen?\n",
      "what happens can happen?\n",
      "what happens can happen?\n",
      "what happens can happen?\n",
      "what happens can happen?\n",
      "Target: but what will actually happen?\n",
      "\n",
      "Source: государства, уточнили в брюсселе?\n",
      "Translation:\n",
      "member states have been put on j brussels.\n",
      "member states have been put on the brussels?\n",
      "member states have been put on jerusalem?\n",
      "member states have been put on j brussels?\n",
      "member states have been put on january?\n",
      "Target: state-owned, said brussels?\n",
      "\n",
      "Source: сегодняшние уроки кубинского ракетного кризиса\n",
      "Translation:\n",
      "this is why the cuban missiles\n",
      "this is why the cuban missiles\n",
      "this is why the cuban missiles\n",
      "this is why the cuban missiles\n",
      "this is why the cuban missiles\n",
      "Target: today\\u0027s lessons from the cuban missile crisis\n",
      "\n",
      "Source: бедность – чрезвычайно динамичное явление.\n",
      "Translation:\n",
      "health is anxtremely dynamic phenomenon of the dynamic\n",
      "health is anxtremely dynamic phenomenon of the region\n",
      "health is anxtremely dynamic phenomenon of the phenomenon\n",
      "health is anxtremely dynamic phenomenon.\n",
      "health is anxtremely dynamic phenomenon of.\n",
      "Target: poverty is an intrinsically dynamic phenomenon.\n",
      "\n",
      "Source: большая ложь гигантов нефти и табака\n",
      "Translation:\n",
      "great lies of the giant and tobacco\n",
      "great lies on tobacco and tobacco\n",
      "great lies from tobacco and tobacco\n",
      "great lies on tobacco and tobacco\n",
      "great lies on tobacco and tobacco\n",
      "Target: big oil, big tobacco, big lies\n",
      "\n",
      "Source: но вылечила ли она основную проблему?\n",
      "Translation:\n",
      "what is it an important problem: the q\n",
      "what is it an important problem: the “\n",
      "what is it an important problem: the j\n",
      "what is it an important problem:?\n",
      "what is it an important problem: the problem?\n",
      "Target: but did it cure the underlying problem?\n",
      "\n",
      "Source: футбол и философия\n",
      "Translation:\n",
      "marxi and philosopher\n",
      "marxi and philosopher\n",
      "marxi and philosopher\n",
      "marxi and philosopher\n",
      "marxi and philosopher\n",
      "Target: football and philosophy\n",
      "\n",
      "Source: лидеры ес не должны сидеть сложа руки.\n",
      "Translation:\n",
      "european leaders should not sit out of their own hands\n",
      "european leaders should not sit out of the hands.\n",
      "european leaders should not sit out of their hands.\n",
      "european leaders should not sit out of a hands.\n",
      "european leaders should not sit out of a position.\n",
      "Target: eu leaders must not sit on their hands.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(valid_iter):\n",
    "        src = batch.src[:1]\n",
    "        src_key_padding_mask = src != SRC.vocab.stoi[\"<pad>\"]\n",
    "        beam = beam_search(model, src, src_key_padding_mask)\n",
    "        \n",
    "        seq = []\n",
    "        for i in range(1, src.size(1)):\n",
    "            sym = SRC.vocab.itos[src[0, i]]\n",
    "            if sym == \"</s>\": break\n",
    "            seq.append(sym)\n",
    "        seq = tok_ru.decode_pieces(seq)\n",
    "        print(\"\\nSource:\", seq)\n",
    "        \n",
    "        print(\"Translation:\")\n",
    "        for pred_proba, pred in beam:                \n",
    "            seq = []\n",
    "            for i in range(1, pred.size(1)):\n",
    "                sym = TGT.vocab.itos[pred[0, i]]\n",
    "                if sym == \"</s>\": break\n",
    "                seq.append(sym)\n",
    "            seq = tok_en.decode_pieces(seq)\n",
    "            print(seq)\n",
    "                \n",
    "        seq = []\n",
    "        for i in range(1, batch.tgt.size(1)):\n",
    "            sym = TGT.vocab.itos[batch.tgt[0, i]]\n",
    "            if sym == \"</s>\": break\n",
    "            seq.append(sym)\n",
    "        seq = tok_en.decode_pieces(seq)\n",
    "        print(\"Target:\", seq)\n",
    "        if i == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jcVpowgppSWt"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "TgGyy85qpSWy",
    "outputId": "9debd289-99f0-4f20-d889-9d254b476882"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/tensor.py:362: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "100%|██████████| 10/10 [54:19<00:00, 327.34s/it]\n"
     ]
    }
   ],
   "source": [
    "hypotheses = []\n",
    "references = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_iter):\n",
    "        #src = batch.src\n",
    "        for src, tgt in zip(batch.src, batch.tgt):\n",
    "          src = src.unsqueeze(0)\n",
    "          src_mask = (src != SRC.vocab.stoi[\"<pad>\"]).unsqueeze(-2)\n",
    "          out = beam_search(model, src, src_mask, \n",
    "                              max_len=40, k=5)\n",
    "          \n",
    "          tgt = tgt.unsqueeze(0)\n",
    "          for (prob, transl), gold in zip(out, tgt):\n",
    "              hyp = []\n",
    "              for i in range(1, transl.size(-1)):\n",
    "                  sym = TGT.vocab.itos[transl[0, i]]\n",
    "                  if sym == \"</s>\": break\n",
    "                  hyp.append(sym)\n",
    "              hypotheses.append(hyp)\n",
    "              \n",
    "              ref = []\n",
    "              for i in range(1, gold.size(-1)):\n",
    "                  sym = TGT.vocab.itos[gold.data[i]]\n",
    "                  if sym == \"</s>\": break\n",
    "                  ref.append(sym)\n",
    "              references.append([ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BODVP_iMVx1F"
   },
   "outputs": [],
   "source": [
    "from nltk import translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R6Up-fGnpSW4",
    "outputId": "2aaa7624-dd7c-4364-9a35-e83dd1e8d2bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10904387763667284"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bleu(references, hypotheses, \n",
    "            smoothing_function=translate.bleu_score.SmoothingFunction().method3,\n",
    "            auto_reweigh=True\n",
    "           )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "assignment7.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
