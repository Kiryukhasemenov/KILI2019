{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "assignment4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J26xzhfHmwag",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 4: Named entity recognition\n",
        "\n",
        "Create a model for Named Entity Recognition for dataset CoNLL 2002.  \n",
        "Your quality metric = f1_macro\n",
        "\n",
        "In your solution you should use: RandomForest, Gradient Boosting (xgboost, lightgbm, catboost)   \n",
        "Tutorials:  \n",
        "1. https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide\n",
        "1. https://github.com/catboost/tutorials \n",
        "\n",
        "More baselines you beat - better your score\n",
        " \n",
        "baseline 1 [3 points]: 0.0604      random labels  \n",
        "baseline 2 [5 points]: 0.3966      PoS features + logistic regression  \n",
        "baseline 3 [8 points]: 0.8122      word2vec cbow embedding + baseline 2 + svm    \n",
        "\n",
        "[1 point] using feature engineering (creating features not presented in the baselines)\n",
        "\n",
        "! Your results must be reproducible. You should explicitly set all seeds random_states in yout model.  \n",
        "! Remember to use proper training pipeline.  \n",
        "\n",
        "bonus, think about:  \n",
        "1. [1 point] Why did we select f1 score with macro averaging as our classification quality measure? What other metrics are suitable?   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHlPEYnlmynP",
        "colab_type": "code",
        "outputId": "ac157850-f72b-4d34-d677-eb2fea0ba4e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!wget 'https://www.dropbox.com/s/0nzylhci63vsfcv/data.zip'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-03 17:51:10--  https://www.dropbox.com/s/0nzylhci63vsfcv/data.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:601f:1::a27d:901\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/0nzylhci63vsfcv/data.zip [following]\n",
            "--2019-12-03 17:51:10--  https://www.dropbox.com/s/raw/0nzylhci63vsfcv/data.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc0a8e0e756c4ecd4bbaf0cc0ada.dl.dropboxusercontent.com/cd/0/inline/AtjsMQdUSxf9B4iYu4Pn9ECqxSp9jr32ecXnFi935qazTCgV3CZb-uiK0UUj7qdMRuNYG5_BSazQSJA565i-Ta5oXG-vJizGMU36B--t1wLT3KdhziAVPjYzWrVoFvZVVAs/file# [following]\n",
            "--2019-12-03 17:51:10--  https://uc0a8e0e756c4ecd4bbaf0cc0ada.dl.dropboxusercontent.com/cd/0/inline/AtjsMQdUSxf9B4iYu4Pn9ECqxSp9jr32ecXnFi935qazTCgV3CZb-uiK0UUj7qdMRuNYG5_BSazQSJA565i-Ta5oXG-vJizGMU36B--t1wLT3KdhziAVPjYzWrVoFvZVVAs/file\n",
            "Resolving uc0a8e0e756c4ecd4bbaf0cc0ada.dl.dropboxusercontent.com (uc0a8e0e756c4ecd4bbaf0cc0ada.dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:601f:6::a27d:906\n",
            "Connecting to uc0a8e0e756c4ecd4bbaf0cc0ada.dl.dropboxusercontent.com (uc0a8e0e756c4ecd4bbaf0cc0ada.dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AtgAEAEA953EN8Yfm4fAVvdUFVMuK-XTFaPbR29jxdZQ1vzJERFS-UHFH0P4PwWjOz-t3iO7rdjnOESVE9jKRfeD4Cw6veCY8JXIZgHkNW3bSgPFtzxnVhwrN00K5vL96Dwa5ztyqi6UAthuUiwmFZ29mT2wIDnQiJXdbwuqROo_Je6MeE1gKJMwUPGrx_4f_TW11AP4KuqH-ZOvg1xOF--4AnpCEdKbN-1hJYVwoEFs0KO-SfHxarJEE3wkTiyf6d3x1OxKoOTPLxVSHUlAjwNVkYecr_iJaKA7Mn_PKzNZzP2ceq2IDQwcjRtWDBUS_mUXwvBoP29AA4HC0HsohL7T-ttEAKUzXgSl1ke1ZWm6eg/file [following]\n",
            "--2019-12-03 17:51:11--  https://uc0a8e0e756c4ecd4bbaf0cc0ada.dl.dropboxusercontent.com/cd/0/inline2/AtgAEAEA953EN8Yfm4fAVvdUFVMuK-XTFaPbR29jxdZQ1vzJERFS-UHFH0P4PwWjOz-t3iO7rdjnOESVE9jKRfeD4Cw6veCY8JXIZgHkNW3bSgPFtzxnVhwrN00K5vL96Dwa5ztyqi6UAthuUiwmFZ29mT2wIDnQiJXdbwuqROo_Je6MeE1gKJMwUPGrx_4f_TW11AP4KuqH-ZOvg1xOF--4AnpCEdKbN-1hJYVwoEFs0KO-SfHxarJEE3wkTiyf6d3x1OxKoOTPLxVSHUlAjwNVkYecr_iJaKA7Mn_PKzNZzP2ceq2IDQwcjRtWDBUS_mUXwvBoP29AA4HC0HsohL7T-ttEAKUzXgSl1ke1ZWm6eg/file\n",
            "Reusing existing connection to uc0a8e0e756c4ecd4bbaf0cc0ada.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1064698 (1.0M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "\rdata.zip              0%[                    ]       0  --.-KB/s               \rdata.zip            100%[===================>]   1.01M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-12-03 17:51:11 (9.90 MB/s) - ‘data.zip’ saved [1064698/1064698]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXj3XXd6wqv2",
        "colab_type": "code",
        "outputId": "3507d6a3-a757-4da2-9eaf-69755e711752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!unzip 'data.zip'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/.DS_Store          \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/data/\n",
            "  inflating: __MACOSX/data/._.DS_Store  \n",
            "  inflating: data/ner_short.csv      \n",
            "  inflating: __MACOSX/data/._ner_short.csv  \n",
            "  inflating: __MACOSX/._data         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tM6Z2rqmwak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn import model_selection\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn import metrics\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "SEED=1337"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFErMs5lmwao",
        "colab_type": "code",
        "outputId": "32335f2c-cfee-4950-a966-afffde9294fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_csv('data/ner_short.csv', index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>1.0</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VBN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>1.0</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>1.0</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NNP</td>\n",
              "      <td>London</td>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>VBP</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>1.0</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  next-next-pos next-next-word next-pos  ... sentence_idx           word tag\n",
              "0           NNS  demonstrators       IN  ...          1.0      Thousands   O\n",
              "1           VBP           have      NNS  ...          1.0             of   O\n",
              "2           VBN        marched      VBP  ...          1.0  demonstrators   O\n",
              "3            IN        through      VBN  ...          1.0           have   O\n",
              "4           NNP         London       IN  ...          1.0        marched   O\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNUAsUlAmwav",
        "colab_type": "code",
        "outputId": "60cab004-3616-41dc-9f61-386a60c3a95c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# number of sentences\n",
        "df.sentence_idx.max()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1500.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d5fgafqmwaz",
        "colab_type": "code",
        "outputId": "7ff33ecd-b2ea-431d-e152-18bad1b63b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# class distribution\n",
        "df.tag.value_counts(normalize=True )"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        0.852828\n",
              "B-geo    0.027604\n",
              "B-gpe    0.020935\n",
              "B-org    0.020247\n",
              "I-per    0.017795\n",
              "B-tim    0.016927\n",
              "B-per    0.015312\n",
              "I-org    0.013937\n",
              "I-geo    0.005383\n",
              "I-tim    0.004247\n",
              "B-art    0.001376\n",
              "I-gpe    0.000837\n",
              "I-art    0.000748\n",
              "B-eve    0.000628\n",
              "I-eve    0.000508\n",
              "B-nat    0.000449\n",
              "I-nat    0.000239\n",
              "Name: tag, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVBO8kf5mwa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sentence length\n",
        "tdf = df.set_index('sentence_idx')\n",
        "tdf['length'] = df.groupby('sentence_idx').tag.count()\n",
        "df = tdf.reset_index(drop=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNlborKhmwa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode categorial variables\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['pos'] = le.fit_transform(df.pos)\n",
        "df['next-pos'] = le.fit_transform(df['next-pos'])\n",
        "df['next-next-pos'] = le.fit_transform(df['next-next-pos'])\n",
        "df['prev-pos'] = le.fit_transform(df['prev-pos'])\n",
        "df['prev-prev-pos'] = le.fit_transform(df['prev-prev-pos'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFIevmj2mwbB",
        "colab_type": "code",
        "outputId": "a554b5f1-e9ff-4ace-e79a-81a05be217fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>40</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>33</td>\n",
              "      <td>have</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>32</td>\n",
              "      <td>marched</td>\n",
              "      <td>33</td>\n",
              "      <td>have</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>through</td>\n",
              "      <td>32</td>\n",
              "      <td>marched</td>\n",
              "      <td>33</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>16</td>\n",
              "      <td>London</td>\n",
              "      <td>9</td>\n",
              "      <td>through</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_idx  next-next-pos next-next-word  ...           word tag  length\n",
              "0           1.0             18  demonstrators  ...      Thousands   O      48\n",
              "1           1.0             33           have  ...             of   O      48\n",
              "2           1.0             32        marched  ...  demonstrators   O      48\n",
              "3           1.0              9        through  ...           have   O      48\n",
              "4           1.0             16         London  ...        marched   O      48\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwqjdBvAmwbD",
        "colab_type": "code",
        "outputId": "83cd15a7-3dca-4814-d705-d6d848898fa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# splitting\n",
        "y = LabelEncoder().fit_transform(df.tag)\n",
        "\n",
        "df_train, df_test, y_train, y_test = model_selection.train_test_split(df, y, stratify=y, \n",
        "                                                                      test_size=0.25, random_state=SEED, shuffle=True)\n",
        "print('train', df_train.shape[0])\n",
        "print('test', df_test.shape[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 50155\n",
            "test 16719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uFChIBkmwbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some wrappers to work with word2vec\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from collections import defaultdict\n",
        "\n",
        "   \n",
        "class Word2VecWrapper(TransformerMixin):\n",
        "    def __init__(self, window=5,negative=5, size=300, iter=100, is_cbow=False, random_state=SEED):\n",
        "        self.window_ = window\n",
        "        self.negative_ = negative\n",
        "        self.size_ = size\n",
        "        self.iter_ = iter\n",
        "        self.is_cbow_ = is_cbow\n",
        "        self.w2v = None\n",
        "        self.random_state = random_state\n",
        "        \n",
        "    def get_size(self):\n",
        "        return self.size_\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        X: list of strings\n",
        "        \"\"\"\n",
        "        sentences_list = [x.split() for x in X]\n",
        "        self.w2v = Word2Vec(sentences_list, \n",
        "                            window=self.window_,\n",
        "                            negative=self.negative_, \n",
        "                            size=self.size_, \n",
        "                            iter=self.iter_,\n",
        "                            sg=not self.is_cbow_, seed=self.random_state)\n",
        "\n",
        "        return self\n",
        "    \n",
        "    def has(self, word):\n",
        "        return word in self.w2v\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        X: a list of words\n",
        "        \"\"\"\n",
        "        if self.w2v is None:\n",
        "            raise Exception('model not fitted')\n",
        "        return np.array([self.w2v[w] if w in self.w2v else np.zeros(self.size_) for w in X ])\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcXvLTHQmwbJ",
        "colab_type": "code",
        "outputId": "6660f0c5-2496-4928-a45a-f9af140b5089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "# here we exploit that word2vec is an unsupervised learning algorithm\n",
        "# so we can train it on the whole dataset (subject to discussion)\n",
        "\n",
        "sentences_list = [x.strip() for x in ' '.join(df.word).split('.')]\n",
        "\n",
        "w2v_cbow = Word2VecWrapper(window=5, negative=5, size=300, iter=300, is_cbow=True, random_state=SEED)\n",
        "w2v_cbow.fit(sentences_list)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 45.6 s, sys: 455 ms, total: 46 s\n",
            "Wall time: 19.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAjPs42FmwbP",
        "colab_type": "code",
        "outputId": "17afdb08-9f95-4e64-f85b-fae055f2b173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "%%time\n",
        "# baseline 1 \n",
        "# random labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "\n",
        "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "\n",
        "model = Pipeline([\n",
        "    ('enc', OneHotEncoder()),\n",
        "    ('est', DummyClassifier(random_state=SEED)),\n",
        "])\n",
        "\n",
        "model.fit(df_train[columns], y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 0.05887736725599869\n",
            "test 0.060439542712750365\n",
            "CPU times: user 131 ms, sys: 13 ms, total: 144 ms\n",
            "Wall time: 160 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uef-pDLimwbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# baseline 2 \n",
        "# pos features + one hot encoding + logistic regression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "\n",
        "model = Pipeline([\n",
        "    ('enc', OneHotEncoder()),\n",
        "    ('est', LogisticRegressionCV(Cs=5, cv=5, n_jobs=-1, scoring='f1_macro', \n",
        "                             penalty='l2', solver='newton-cg', multi_class='multinomial', random_state=SEED)),\n",
        "])\n",
        "\n",
        "model.fit(df_train[columns], y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6jCiWSjmwbV",
        "colab_type": "code",
        "outputId": "0eca5e7a-6a2a-4542-85d3-c44e709d0981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "%%time\n",
        "# baseline 3\n",
        "# use word2vec cbow embedding + baseline 2 + svm\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.svm import LinearSVC\n",
        "import scipy.sparse as sp\n",
        "\n",
        "embeding = w2v_cbow\n",
        "encoder_pos = OneHotEncoder()\n",
        "X_train = sp.hstack([\n",
        "    embeding.transform(df_train.word),\n",
        "    embeding.transform(df_train['next-word']),\n",
        "    embeding.transform(df_train['next-next-word']),\n",
        "    embeding.transform(df_train['prev-word']),\n",
        "    embeding.transform(df_train['prev-prev-word']),\n",
        "    encoder_pos.fit_transform(df_train[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\n",
        "])\n",
        "X_test = sp.hstack([\n",
        "    embeding.transform(df_test.word),\n",
        "    embeding.transform(df_test['next-word']),\n",
        "    embeding.transform(df_test['next-next-word']),\n",
        "    embeding.transform(df_test['prev-word']),\n",
        "    embeding.transform(df_test['prev-prev-word']),\n",
        "    encoder_pos.transform(df_test[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\n",
        "])\n",
        "\n",
        "model = model_selection.GridSearchCV(LinearSVC(penalty='l2', multi_class='ovr', random_state=SEED), \n",
        "                                    {'C': np.logspace(-4, 0, 5)}, \n",
        "                                    cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(X_train), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(X_test), average='macro'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 14.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train 0.9556044410366434\n",
            "test 0.7969558492427843\n",
            "CPU times: user 2min 53s, sys: 1.39 s, total: 2min 54s\n",
            "Wall time: 17min 47s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YP8KkUN2IvN",
        "colab_type": "text"
      },
      "source": [
        "# My attempt\n",
        "\n",
        "## 1st Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx1yoDR--E3H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "725cdf00-caf5-47f4-a16c-dda025d39629"
      },
      "source": [
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (0.20)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.1.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.25.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.1.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (41.6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7v7Cye0-FvK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "33c1c647-fda7-422b-cc9f-951c85efeee2"
      },
      "source": [
        "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "\n",
        "model = Pipeline([\n",
        "    ('enc', OneHotEncoder()),\n",
        "    ('catboost', CatBoostClassifier(max_depth=2, learning_rate=0.1, n_estimators=100, random_state=SEED))\n",
        "])\n",
        "\n",
        "model.fit(df_train[columns], y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 1.6170229\ttotal: 92.6ms\tremaining: 9.16s\n",
            "1:\tlearn: 1.3519441\ttotal: 135ms\tremaining: 6.61s\n",
            "2:\tlearn: 1.1811594\ttotal: 176ms\tremaining: 5.69s\n",
            "3:\tlearn: 1.0489582\ttotal: 218ms\tremaining: 5.22s\n",
            "4:\tlearn: 0.9508875\ttotal: 259ms\tremaining: 4.92s\n",
            "5:\tlearn: 0.8714600\ttotal: 303ms\tremaining: 4.75s\n",
            "6:\tlearn: 0.8021421\ttotal: 352ms\tremaining: 4.67s\n",
            "7:\tlearn: 0.7437787\ttotal: 395ms\tremaining: 4.54s\n",
            "8:\tlearn: 0.6951005\ttotal: 438ms\tremaining: 4.42s\n",
            "9:\tlearn: 0.6528017\ttotal: 479ms\tremaining: 4.31s\n",
            "10:\tlearn: 0.6166551\ttotal: 524ms\tremaining: 4.24s\n",
            "11:\tlearn: 0.5853460\ttotal: 567ms\tremaining: 4.16s\n",
            "12:\tlearn: 0.5577028\ttotal: 610ms\tremaining: 4.08s\n",
            "13:\tlearn: 0.5335604\ttotal: 652ms\tremaining: 4s\n",
            "14:\tlearn: 0.5134325\ttotal: 693ms\tremaining: 3.93s\n",
            "15:\tlearn: 0.4947187\ttotal: 736ms\tremaining: 3.86s\n",
            "16:\tlearn: 0.4777833\ttotal: 778ms\tremaining: 3.8s\n",
            "17:\tlearn: 0.4629193\ttotal: 818ms\tremaining: 3.73s\n",
            "18:\tlearn: 0.4497529\ttotal: 859ms\tremaining: 3.66s\n",
            "19:\tlearn: 0.4386346\ttotal: 901ms\tremaining: 3.6s\n",
            "20:\tlearn: 0.4279558\ttotal: 945ms\tremaining: 3.55s\n",
            "21:\tlearn: 0.4187078\ttotal: 987ms\tremaining: 3.5s\n",
            "22:\tlearn: 0.4060628\ttotal: 1.03s\tremaining: 3.44s\n",
            "23:\tlearn: 0.3985542\ttotal: 1.08s\tremaining: 3.44s\n",
            "24:\tlearn: 0.3918021\ttotal: 1.13s\tremaining: 3.4s\n",
            "25:\tlearn: 0.3835916\ttotal: 1.18s\tremaining: 3.35s\n",
            "26:\tlearn: 0.3778575\ttotal: 1.22s\tremaining: 3.3s\n",
            "27:\tlearn: 0.3726391\ttotal: 1.26s\tremaining: 3.24s\n",
            "28:\tlearn: 0.3680811\ttotal: 1.3s\tremaining: 3.19s\n",
            "29:\tlearn: 0.3632972\ttotal: 1.35s\tremaining: 3.15s\n",
            "30:\tlearn: 0.3597508\ttotal: 1.4s\tremaining: 3.11s\n",
            "31:\tlearn: 0.3554201\ttotal: 1.44s\tremaining: 3.06s\n",
            "32:\tlearn: 0.3526031\ttotal: 1.48s\tremaining: 3s\n",
            "33:\tlearn: 0.3499451\ttotal: 1.52s\tremaining: 2.95s\n",
            "34:\tlearn: 0.3462171\ttotal: 1.56s\tremaining: 2.91s\n",
            "35:\tlearn: 0.3440008\ttotal: 1.61s\tremaining: 2.86s\n",
            "36:\tlearn: 0.3408736\ttotal: 1.65s\tremaining: 2.81s\n",
            "37:\tlearn: 0.3392143\ttotal: 1.69s\tremaining: 2.76s\n",
            "38:\tlearn: 0.3364772\ttotal: 1.73s\tremaining: 2.71s\n",
            "39:\tlearn: 0.3339614\ttotal: 1.78s\tremaining: 2.66s\n",
            "40:\tlearn: 0.3324928\ttotal: 1.82s\tremaining: 2.62s\n",
            "41:\tlearn: 0.3314239\ttotal: 1.86s\tremaining: 2.57s\n",
            "42:\tlearn: 0.3300262\ttotal: 1.9s\tremaining: 2.52s\n",
            "43:\tlearn: 0.3281767\ttotal: 1.94s\tremaining: 2.47s\n",
            "44:\tlearn: 0.3273247\ttotal: 1.98s\tremaining: 2.42s\n",
            "45:\tlearn: 0.3263092\ttotal: 2.03s\tremaining: 2.38s\n",
            "46:\tlearn: 0.3254658\ttotal: 2.07s\tremaining: 2.33s\n",
            "47:\tlearn: 0.3243257\ttotal: 2.11s\tremaining: 2.29s\n",
            "48:\tlearn: 0.3227985\ttotal: 2.15s\tremaining: 2.24s\n",
            "49:\tlearn: 0.3210417\ttotal: 2.19s\tremaining: 2.19s\n",
            "50:\tlearn: 0.3193238\ttotal: 2.24s\tremaining: 2.15s\n",
            "51:\tlearn: 0.3184223\ttotal: 2.28s\tremaining: 2.1s\n",
            "52:\tlearn: 0.3176119\ttotal: 2.32s\tremaining: 2.06s\n",
            "53:\tlearn: 0.3170130\ttotal: 2.37s\tremaining: 2.02s\n",
            "54:\tlearn: 0.3158823\ttotal: 2.41s\tremaining: 1.97s\n",
            "55:\tlearn: 0.3138487\ttotal: 2.45s\tremaining: 1.93s\n",
            "56:\tlearn: 0.3127092\ttotal: 2.49s\tremaining: 1.88s\n",
            "57:\tlearn: 0.3121865\ttotal: 2.54s\tremaining: 1.84s\n",
            "58:\tlearn: 0.3116656\ttotal: 2.58s\tremaining: 1.79s\n",
            "59:\tlearn: 0.3104638\ttotal: 2.62s\tremaining: 1.75s\n",
            "60:\tlearn: 0.3088023\ttotal: 2.67s\tremaining: 1.7s\n",
            "61:\tlearn: 0.3082070\ttotal: 2.71s\tremaining: 1.66s\n",
            "62:\tlearn: 0.3076553\ttotal: 2.75s\tremaining: 1.61s\n",
            "63:\tlearn: 0.3070624\ttotal: 2.79s\tremaining: 1.57s\n",
            "64:\tlearn: 0.3066925\ttotal: 2.83s\tremaining: 1.52s\n",
            "65:\tlearn: 0.3058697\ttotal: 2.88s\tremaining: 1.48s\n",
            "66:\tlearn: 0.3044990\ttotal: 2.92s\tremaining: 1.44s\n",
            "67:\tlearn: 0.3040784\ttotal: 2.96s\tremaining: 1.39s\n",
            "68:\tlearn: 0.3036776\ttotal: 3s\tremaining: 1.35s\n",
            "69:\tlearn: 0.3029601\ttotal: 3.04s\tremaining: 1.3s\n",
            "70:\tlearn: 0.3021564\ttotal: 3.08s\tremaining: 1.26s\n",
            "71:\tlearn: 0.3018318\ttotal: 3.13s\tremaining: 1.22s\n",
            "72:\tlearn: 0.3015692\ttotal: 3.17s\tremaining: 1.17s\n",
            "73:\tlearn: 0.3007402\ttotal: 3.21s\tremaining: 1.13s\n",
            "74:\tlearn: 0.2999845\ttotal: 3.25s\tremaining: 1.08s\n",
            "75:\tlearn: 0.2993256\ttotal: 3.3s\tremaining: 1.04s\n",
            "76:\tlearn: 0.2990464\ttotal: 3.34s\tremaining: 997ms\n",
            "77:\tlearn: 0.2987740\ttotal: 3.38s\tremaining: 954ms\n",
            "78:\tlearn: 0.2980328\ttotal: 3.42s\tremaining: 910ms\n",
            "79:\tlearn: 0.2976166\ttotal: 3.47s\tremaining: 867ms\n",
            "80:\tlearn: 0.2972075\ttotal: 3.51s\tremaining: 823ms\n",
            "81:\tlearn: 0.2969673\ttotal: 3.55s\tremaining: 780ms\n",
            "82:\tlearn: 0.2962409\ttotal: 3.59s\tremaining: 736ms\n",
            "83:\tlearn: 0.2956246\ttotal: 3.64s\tremaining: 693ms\n",
            "84:\tlearn: 0.2953216\ttotal: 3.68s\tremaining: 649ms\n",
            "85:\tlearn: 0.2949880\ttotal: 3.72s\tremaining: 606ms\n",
            "86:\tlearn: 0.2944188\ttotal: 3.76s\tremaining: 562ms\n",
            "87:\tlearn: 0.2941256\ttotal: 3.81s\tremaining: 519ms\n",
            "88:\tlearn: 0.2939781\ttotal: 3.85s\tremaining: 475ms\n",
            "89:\tlearn: 0.2937146\ttotal: 3.89s\tremaining: 432ms\n",
            "90:\tlearn: 0.2935054\ttotal: 3.93s\tremaining: 389ms\n",
            "91:\tlearn: 0.2931289\ttotal: 3.97s\tremaining: 346ms\n",
            "92:\tlearn: 0.2928170\ttotal: 4.01s\tremaining: 302ms\n",
            "93:\tlearn: 0.2925221\ttotal: 4.05s\tremaining: 259ms\n",
            "94:\tlearn: 0.2922644\ttotal: 4.1s\tremaining: 216ms\n",
            "95:\tlearn: 0.2920287\ttotal: 4.14s\tremaining: 173ms\n",
            "96:\tlearn: 0.2914559\ttotal: 4.18s\tremaining: 129ms\n",
            "97:\tlearn: 0.2911275\ttotal: 4.23s\tremaining: 86.3ms\n",
            "98:\tlearn: 0.2909435\ttotal: 4.27s\tremaining: 43.1ms\n",
            "99:\tlearn: 0.2905486\ttotal: 4.31s\tremaining: 0us\n",
            "train 0.2556525016256053\n",
            "test 0.2571834203700006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_l7m7zh-TPZ",
        "colab_type": "text"
      },
      "source": [
        "## 2nd Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2JoBC-E-wdZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7b4b49d1-407d-41f1-bff0-3af73e809518"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(df_train[columns], y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 0.7335988817212311\n",
            "test 0.5759655316473205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLL-XIyO_MBc",
        "colab_type": "text"
      },
      "source": [
        "## 3rd Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vZ912Lg3Mow",
        "colab_type": "code",
        "outputId": "e0a88d09-e7c6-4e7c-de3f-eaadea8ebf99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import scipy as sp\n",
        "\n",
        "embeding = w2v_cbow\n",
        "encoder_pos = OneHotEncoder()\n",
        "X_train = sp.hstack([\n",
        "    embeding.transform(df_train.word),\n",
        "    embeding.transform(df_train['next-word']),\n",
        "    embeding.transform(df_train['next-next-word']),\n",
        "    embeding.transform(df_train['prev-word']),\n",
        "    embeding.transform(df_train['prev-prev-word'])\n",
        "])\n",
        "X_test = sp.hstack([\n",
        "    embeding.transform(df_test.word),\n",
        "    embeding.transform(df_test['next-word']),\n",
        "    embeding.transform(df_test['next-next-word']),\n",
        "    embeding.transform(df_test['prev-word']),\n",
        "    embeding.transform(df_test['prev-prev-word'])\n",
        "])\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(random_state=SEED)\n",
        "\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=1337,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8OPSsIlJIoN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c19f919a-30a6-4a49-c9a4-e8ea2a3bb0a1"
      },
      "source": [
        "print('train', metrics.f1_score(y_train, np.around(model.predict(X_train), 0), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, np.around(model.predict(X_test), 0), average='macro'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 0.9599068191956531\n",
            "test 0.7995809915324726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBvirYkv2wGO",
        "colab_type": "text"
      },
      "source": [
        "# Metrics choice\n",
        "F1 was chosen because it combines two main metrics - precision and recall, which both are key metrics for classification tasks. It can be substituted by visualising the precision-recall curve as well.\n",
        "\n",
        "`weighted` param is chosen because it demonstrates the \"grouping\" of the predicted labels. It is necessary for multiclass classification. \n",
        "\n",
        "We could use other `average` parameter, e.g. `macro` or `micro`, but in this case we will lose the information about the \"grouping\" of each label's distribution."
      ]
    }
  ]
}